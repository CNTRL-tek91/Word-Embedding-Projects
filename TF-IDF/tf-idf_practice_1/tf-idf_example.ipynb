{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e37b93f",
   "metadata": {},
   "source": [
    "# TF-IDF Word Embedding #1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd9ce9d",
   "metadata": {},
   "source": [
    "### 1. Importing libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a61fbe20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c66ba7",
   "metadata": {},
   "source": [
    "### 2. Load documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc99a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The sky is blue and beautiful.', 'Love this blue and beautiful sky!', 'The quick brown fox jumps over the lazy dog.', \"A king's breakfast has sausages, ham, bacon, eggs, toast and beans.\", 'I love green eggs, ham, sausages and bacon!', 'The brown fox is quick and the blue dog is lazy!', 'The sky is very blue and the sky is very beautiful today.']\n"
     ]
    }
   ],
   "source": [
    "with open('documents.txt', 'r', encoding = 'utf-8') as f:\n",
    "    documents = f.readlines()\n",
    "\n",
    "documents = [doc.strip() for doc in documents if doc.strip()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540471dd",
   "metadata": {},
   "source": [
    "### 3. Initialize TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b7333ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words= 'english')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c3dd3e",
   "metadata": {},
   "source": [
    "### 4. Fit & Transform documents to TF-IDF matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33b88755",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix = vectorizer.fit_transform(documents)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae740cb",
   "metadata": {},
   "source": [
    "### 5. Feature names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a7d7c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary:  ['bacon' 'beans' 'beautiful' 'blue' 'breakfast' 'brown' 'dog' 'eggs' 'fox'\n",
      " 'green' 'ham' 'jumps' 'king' 'lazy' 'love' 'quick' 'sausages' 'sky'\n",
      " 'toast' 'today']\n"
     ]
    }
   ],
   "source": [
    "print(\"Vocabulary: \", vectorizer.get_feature_names_out())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e211fc",
   "metadata": {},
   "source": [
    "### 6. Converting TF-IDF matrix to dense form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7f08577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.30073434 0.         0.         0.44920459 0.39000294 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.44920459 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.44920459 0.39000294 0.\n",
      "  0.         0.         0.        ]\n",
      " [0.26144771 0.         0.         0.39052245 0.33905465 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.45687599\n",
      "  0.         0.         0.         0.39052245 0.         0.55039605\n",
      "  0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.31457246 0.31457246 0.         0.31457246 0.         0.\n",
      "  0.         0.         0.37896375 0.         0.31457246 0.\n",
      "  0.37896375 0.31457246 0.         0.         0.46689805 0.\n",
      "  0.         0.         0.        ]\n",
      " [0.16813526 0.29381386 0.35395598 0.         0.         0.35395598\n",
      "  0.         0.         0.29381386 0.         0.         0.29381386\n",
      "  0.35395598 0.         0.         0.35395598 0.         0.\n",
      "  0.         0.         0.29381386 0.         0.         0.\n",
      "  0.35395598 0.         0.        ]\n",
      " [0.21979174 0.3840828  0.         0.         0.         0.\n",
      "  0.         0.         0.3840828  0.         0.46270249 0.3840828\n",
      "  0.         0.         0.         0.         0.         0.3840828\n",
      "  0.         0.         0.3840828  0.         0.         0.\n",
      "  0.         0.         0.        ]\n",
      " [0.17251151 0.         0.         0.         0.22371904 0.\n",
      "  0.30146131 0.30146131 0.         0.30146131 0.         0.\n",
      "  0.         0.51535826 0.         0.         0.30146131 0.\n",
      "  0.         0.30146131 0.         0.         0.44743808 0.\n",
      "  0.         0.         0.        ]\n",
      " [0.13914681 0.         0.         0.20784252 0.1804505  0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.41568504 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.41568504 0.360901   0.\n",
      "  0.         0.2929299  0.5858598 ]]\n"
     ]
    }
   ],
   "source": [
    "dense_matrix = tfidf_matrix.todense()\n",
    "\n",
    "print(dense_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0e2a6f",
   "metadata": {},
   "source": [
    "### 7. Calculating Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa6680e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity:\n",
      "[[1.         0.56170756 0.18209161 0.05056405 0.06609892 0.54513468\n",
      "  0.71979396]\n",
      " [0.56170756 1.         0.         0.04395858 0.23294226 0.12095572\n",
      "  0.3410637 ]\n",
      " [0.18209161 0.         1.         0.         0.         0.68306509\n",
      "  0.16850397]\n",
      " [0.05056405 0.04395858 0.         1.         0.48835015 0.02900527\n",
      "  0.02339548]\n",
      " [0.06609892 0.23294226 0.         0.48835015 1.         0.03791661\n",
      "  0.03058332]\n",
      " [0.54513468 0.12095572 0.68306509 0.02900527 0.03791661 1.\n",
      "  0.44008221]\n",
      " [0.71979396 0.3410637  0.16850397 0.02339548 0.03058332 0.44008221\n",
      "  1.        ]]\n"
     ]
    }
   ],
   "source": [
    "cosine_sim = cosine_similarity(tfidf_matrix)\n",
    "\n",
    "print(\"Cosine Similarity:\" )\n",
    "print(cosine_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad97697",
   "metadata": {},
   "source": [
    "### Finding most similar document to the first one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ac68d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar to document 0: document 6\n",
      "doc 0:  The sky is blue and beautiful.\n",
      "doc 6 : The sky is very blue and the sky is very beautiful today.\n"
     ]
    }
   ],
   "source": [
    "most_sim = np.argsort(cosine_sim[0])[::-1][1]\n",
    "print(f\"Most similar to document 0: document {most_sim}\")\n",
    "print(\"doc 0: \", documents[0])\n",
    "print(\"doc\", most_sim, \":\", documents[most_sim])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
